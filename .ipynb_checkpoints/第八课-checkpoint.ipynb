{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第八次读书笔记+作业\n",
    "\n",
    "学号：20179065 $ \\qquad $ 班级序列号：170230 $ \\qquad $ 姓名：董秩序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 偏最小二乘回归建模原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设有 q个因变量${y1,…,yq}$和p自变量${x1,…,xp}$。\n",
    "为了研究因变量和自变量的统计关系,观测了n个样本点,\n",
    "由此构成了自变量与因变量的数据表$X={x1,…,xp}和.Y={y1,…,yp}$。\n",
    "\n",
    "偏最小二乘回归分别在X与Y中提取出成分t1和u1，即t1是$x1,x2,…,xq$的线形组合, \n",
    "u1是$y1,y2,…,yp$的线形组合.\n",
    "在提取这两个成分时,为了回归分析的需要,有下列两个要求:\n",
    "   * t1和u1应尽可能大地携带他们各自数据表中的变异信息\n",
    "   * t1与u1的相关程度能够达到最大。\n",
    "  \n",
    "在第一个成分t1和u1被提取后，偏最小二乘回归分别实施X对t1的回归以及Y对u1的回归。\n",
    "如果回归方程已经达到满意的精度，则算法终止；否则,将利用*X被t1解释后的残余信息*以及*Y 被t2解释后的残余信息*进行第二轮的成分提取。\n",
    "\n",
    "如此往复，直到能达到一个较满意的精度为止。若最终对 X共提取了m个成分$t1,t2,…,tm$，偏最小二乘回归将通过实施yk对$t1,t2,…,tm$的回归,然后再表达成yk关于原变量$X1,X2,…,Xq$的回归方程$(k=1,2,…,p)$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推导偏最小二乘回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step1:数据说明与标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据矩阵$E0，F0$，\n",
    "其中E0为自变量矩阵，F0是因变量矩阵，每一行是一个样例，每一列代表了一个维度的变量；\n",
    "\n",
    "数据标准化即**数据中心化**，对每个样本都做如下操作：\n",
    "减去一个维度变量的均值除以该维度的标准差。\n",
    "\n",
    "以下设E0，F0都为标准化了的数据。即：\n",
    "自变量经标准化处理后的数据矩阵记为$E0（n*m）$，\n",
    "因变量经标准化处理后的数据矩阵记为$F0（n*p）$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step2:求符合要求的主成分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "即求自变量与因变量的第一对主成分t1和u1。因为方差最大则表示的信息就越多,所以\n",
    "要求t1与u1的协方差达到最大，即：\n",
    "\n",
    "$Cov(t1,u1)-> max$\n",
    "\n",
    "而且，$t1$是X的线性组合，那么权重系数设为$W1$，即$t1 = E0W1$，同理，$u1$是Y的线性组合，$u1 = F0C1$。同时又要求，W1与C1同为单位向量:\n",
    "\n",
    "\n",
    "$max<E0w1,F0c1> S.T. ∥w1∥=1;∥c1∥=1$\n",
    "\n",
    "通过拉格朗日求解，得$w1$就是矩阵$E0'F0F0'E0$的对应于最大特征值的特征向量，$c1$就是矩阵$F0’E0E0’F0$对应于最大特征值的最大特征向量，均单位化。\n",
    "\n",
    "有了权系数$w1，c1$，可以求得主成分$t1，u1$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step3:建立主成分与原自变量、因变量之间的回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立E0，F0对$t1，u1$的三个回归方程:\n",
    "\n",
    "$E0=t1p1+E1$\n",
    "\n",
    "$F0=u1q1+F^*1$\n",
    "\n",
    "$F0=t1r1+F1$\n",
    "\n",
    "$E1,F^*1,F1$分别是三个回归方程的残差矩阵."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step4:继续求主成分，直到满足要求"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用残差矩阵E1和F1取代E0和F0,然后,求第二个轴$w2和c2$以及第二个成分$t2,u2$,有:\n",
    "\n",
    "$t2=E1w2$ \n",
    "\n",
    "$u2=F1c2$\n",
    "\n",
    "重复执行step3。直到求出所有主成分或者满足要求。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step5:推导因变量之于自变量的回归表达式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若E0的秩为A，则可以求出：\n",
    "\n",
    "$E_0=t_1p'1+Λ+t_Ap'_A$\n",
    "\n",
    "$F_0=t_1r'1+Λ+t_Ar'_A+F_A$\n",
    "\n",
    "由于$t1….tA$都可以表示$E01，E02….E0q$的线性组合，那么就可以还原成：\n",
    "$y_k^*=ak_1x_1+Λ+ak_px'_p+FA_k \\qquad k =1,2,...q$ \n",
    "\n",
    "$Fa_k$为残差矩阵Fa的第k列。这样，就求出了回归方程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure of NIPALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inner loop of the iterative NIPALS algorithm\n",
    "NIPALS迭代算法的内循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _nipals_twoblocks_inner_loop(X, Y, max_iter=500, tol=1e-06,):  \n",
    "    y_score = Y[:, [0]] \n",
    "    x_weights_old = 0\n",
    "    ite = 1\n",
    "\n",
    "    while True:\n",
    "        x_weights = np.dot(X.T, y_score) / np.dot(y_score.T, y_score) \n",
    "        x_weights /= np.sqrt(np.dot(x_weights.T, x_weights)) \n",
    "        x_score = np.dot(X, x_weights) \n",
    "        y_weights = np.dot(Y.T, x_score) / np.dot(x_score.T, x_score) \n",
    "        y_score = np.dot(Y, y_weights) / np.dot(y_weights.T, y_weights) \n",
    "        x_weights_diff = x_weights - x_weights_old\n",
    "        if np.dot(x_weights_diff.T, x_weights_diff) < tol :\n",
    "            break\n",
    "\n",
    "        if ite == max_iter:\n",
    "            warnings.warn('Maximum number of iterations reached')\n",
    "            break\n",
    "        x_weights_old = x_weights\n",
    "        ite += 1\n",
    "\n",
    "    return x_weights, y_weights  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Center X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _center_xy(X, Y):      \n",
    "\n",
    "    # center\n",
    "    x_mean = X.mean(axis=0)\n",
    "    X_center = np.subtract(X, x_mean)\n",
    "    y_mean = Y.mean(axis=0)\n",
    "    Y_center = np.subtract(Y, y_mean)\n",
    "\n",
    "    return X_center, Y_center, x_mean, y_mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NIPALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _NIPALS(): \n",
    "    def __init__(self, n_components, max_iter=500, tol=1e-06, copy=True):\n",
    "        self.n_components = n_components\n",
    "        self.max_iter = max_iter         \n",
    "        self.tol = tol\n",
    "        self.copy = copy\n",
    "\n",
    "    def fit(self, X, Y, n_components):    \n",
    "        n = X.shape[0]\n",
    "        p = X.shape[1]\n",
    "        q = Y.shape[1]\n",
    "\n",
    "        if n != Y.shape[0]:    \n",
    "                'Incompatible shapes: X has %s samples, while Y '\n",
    "                'has %s' % (X.shape[0], Y.shape[0])\n",
    "        if self.n_components < 1 or self.n_components > p: \n",
    "            raise ValueError('invalid number of components')\n",
    "\n",
    "        Xcenter, Ycenter, self.x_mean_, self.y_mean_ = _center_xy(X, Y) \n",
    "        # Residuals (deflated) matrices\n",
    "        Xk = Xcenter\n",
    "        Yk = Ycenter\n",
    "        # Results matrices\n",
    "        self.x_scores_ = np.zeros((n, self.n_components))  \n",
    "        self.y_scores_ = np.zeros((n, self.n_components))  \n",
    "        self.x_weights_ = np.zeros((p, self.n_components)) \n",
    "        self.y_weights_ = np.zeros((q, self.n_components)) \n",
    "        self.x_loadings_ = np.zeros((p, self.n_components)) \n",
    "        self.y_loadings_ = np.zeros((q, self.n_components))\n",
    " \n",
    "        # NIPALS algo: outer loop, over components\n",
    "        for k in range(self.n_components):\n",
    "            x_weights, y_weights = _nipals_twoblocks_inner_loop(\n",
    "                    X=Xk, Y=Yk, max_iter=self.max_iter, tol=self.tol,)\n",
    "            # compute scores\n",
    "            x_scores = np.dot(Xk, x_weights) \n",
    "            y_ss = np.dot(y_weights.T, y_weights)\n",
    "            y_scores = np.dot(Yk, y_weights) / y_ss  \n",
    "            x_loadings = np.dot(Xk.T, x_scores) / np.dot(x_scores.T, x_scores)\n",
    "            # - substract rank-one approximations to obtain remainder matrix\n",
    "            Xk -= np.dot(x_scores, x_loadings.T)\n",
    "\n",
    "            y_loadings = (np.dot(Yk.T, x_scores) / np.dot(x_scores.T, x_scores))\n",
    "            Yk -= np.dot(x_scores, y_loadings.T)\n",
    "            self.x_scores_[:, k] = x_scores.ravel()  # T    \n",
    "            self.y_scores_[:, k] = y_scores.ravel()  # U   \n",
    "            self.x_weights_[:, k] = x_weights.ravel()  # W   \n",
    "            self.y_weights_[:, k] = y_weights.ravel()  # C   \n",
    "            self.x_loadings_[:, k] = x_loadings.ravel()  # P \n",
    "            self.y_loadings_[:, k] = y_loadings.ravel()  # Q \n",
    "           \n",
    "        lists_coefs = []              \n",
    "        for i in range(n_components):   \n",
    "            self.x_rotations_ = np.dot(self.x_weights_[:, :i + 1], linalg.inv(np.dot(self.x_loadings_[:, :i + 1].T, self.x_weights_[:, :i + 1])))\n",
    "            self.coefs = np.dot(self.x_rotations_, self.y_loadings_[:, :i + 1].T)\n",
    "             \n",
    "            lists_coefs.append(self.coefs)\n",
    "        \n",
    "        return lists_coefs \n",
    "\n",
    "    def predict(self, x_test, coefs_B, xtr_mean, ytr_mean):\n",
    "\n",
    "        xte_center = np.subtract(x_test, xtr_mean)\n",
    "        y_pre = np.dot(xte_center, coefs_B)\n",
    "        y_predict = np.add(y_pre, ytr_mean)          \n",
    " \n",
    "        return y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "#from cross_validation import Cross_Validation\n",
    "#from NIPALS import _NIPALS\n",
    "import numpy as np\n",
    " \n",
    "class PLS():\n",
    "    def __init__(self, x_train, y_train, x_test, y_test, n_fold=10, max_components=10):\n",
    "        self.x_train = x_train\n",
    "        self.x_test = x_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.n_fold = n_fold\n",
    "        self.max_components = max_components\n",
    "                                            \n",
    "    def pls(self):\n",
    "\t    # Select the optimal principal component number\n",
    "        pls_cv = cross_val_score(self.x_train, self.y_train, self.n_fold, self.max_components)\n",
    "        y_allPredict, y_measure = pls_cv.predict_cv()\n",
    "        RMSECV, min_RMSECV, comp_best = pls_cv.mse_cv(y_allPredict, y_measure)\n",
    "        #  Modeling by optimal principal component number\n",
    "        pls = _NIPALS(comp_best)\n",
    "        List_coef_B = pls.fit(self.x_train, self.y_train, comp_best)\n",
    "        coef_B = List_coef_B[comp_best - 1]\n",
    "        x_trainMean = np.mean(self.x_train, axis=0)\n",
    "        y_trainMean = np.mean(self.y_train, axis=0)\n",
    "        y_trainPredict = pls.predict(self.x_train, coef_B, x_trainMean, y_trainMean)\n",
    "        # compute RMSEC\n",
    "        press = np.square(np.subtract(self.y_train, y_trainPredict))\n",
    "        all_press = np.sum(press, axis=0)\n",
    "        RMSEC = np.sqrt(all_press / self.x_train.shape[0])\n",
    "         # compute RMSEP\n",
    "        y_predict = pls.predict(self.x_test, coef_B, x_trainMean, y_trainMean)\n",
    "        press = np.square(np.subtract(self.y_test, y_predict))\n",
    "        all_press = np.sum(press, axis=0)\n",
    "        RMSEP = np.sqrt(all_press / self.x_test.shape[0])\n",
    "        \n",
    "        return RMSECV, min_RMSECV, comp_best, RMSEC, RMSEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'm5', 'mp5', 'mp6', 'water', 'pro', 'oil', 'starch'])\n",
      "(80, 700) (80, 1)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "estimator should be an estimator implementing 'fit' method, array([[0.0454611, 0.0453212, 0.0452048, ..., 0.700463 , 0.700174 ,\n        0.699682 ],\n       [0.0497307, 0.0495645, 0.0494652, ..., 0.794257 , 0.793772 ,\n        0.793419 ],\n       [0.056241 , 0.0560315, 0.055933 , ..., 0.785709 , 0.785336 ,\n        0.784926 ],\n       ...,\n       [0.0409112, 0.0407533, 0.0406416, ..., 0.74045  , 0.740256 ,\n        0.739964 ],\n       [0.0473355, 0.0471002, 0.0470358, ..., 0.727989 , 0.727612 ,\n        0.727407 ],\n       [0.0461938, 0.0459604, 0.0458929, ..., 0.711218 , 0.711062 ,\n        0.71042  ]]) was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-800ec67e052f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mdemo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_fold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mRMSECV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_RMSECV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomp_best\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRMSEC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRMSEP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdemo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RMSECV'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRMSECV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'min_RMSECV'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_RMSECV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-1d5c2aa03aa1>\u001b[0m in \u001b[0;36mpls\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[1;31m# Select the optimal principal component number\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mpls_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_fold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_components\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0my_allPredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_measure\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpls_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mRMSECV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_RMSECV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomp_best\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpls_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_allPredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_measure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \"\"\"\n\u001b[0;32m    383\u001b[0m     \u001b[1;31m# To ensure multimetric format is not supported\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n",
      "\u001b[1;32mD:\\Users\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[1;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         raise TypeError(\"estimator should be an estimator implementing \"\n\u001b[1;32m--> 270\u001b[1;33m                         \"'fit' method, %r was passed\" % estimator)\n\u001b[0m\u001b[0;32m    271\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mget_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: estimator should be an estimator implementing 'fit' method, array([[0.0454611, 0.0453212, 0.0452048, ..., 0.700463 , 0.700174 ,\n        0.699682 ],\n       [0.0497307, 0.0495645, 0.0494652, ..., 0.794257 , 0.793772 ,\n        0.793419 ],\n       [0.056241 , 0.0560315, 0.055933 , ..., 0.785709 , 0.785336 ,\n        0.784926 ],\n       ...,\n       [0.0409112, 0.0407533, 0.0406416, ..., 0.74045  , 0.740256 ,\n        0.739964 ],\n       [0.0473355, 0.0471002, 0.0470358, ..., 0.727989 , 0.727612 ,\n        0.727407 ],\n       [0.0461938, 0.0459604, 0.0458929, ..., 0.711218 , 0.711062 ,\n        0.71042  ]]) was passed"
     ]
    }
   ],
   "source": [
    "#from sklearn.cross_validation import train_test_split这个包没有用了\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io.matlab.mio import loadmat\n",
    "##from PLS.PLS import PLS \n",
    "if __name__ == '__main__':\n",
    "    fname = loadmat('E:\\Documents\\DAY\\基于python的数据分析\\data\\cornmat.mat')\n",
    "    print(fname.keys())\n",
    "    #x = fname['cornspect']\n",
    "    x = fname['m5']\n",
    "    #y = fname['cornprop'][:, 0:1]\n",
    "    y = fname['pro'][:, 0:1]\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)  \n",
    "    demo = PLS(x_train, y_train, x_test, y_test, n_fold=10, max_components=9)\n",
    "    RMSECV, min_RMSECV, comp_best, RMSEC, RMSEP = demo.pls()\n",
    "    print('RMSECV', RMSECV)\n",
    "    print('min_RMSECV', min_RMSECV)   \n",
    "    print('comp_best', comp_best)\n",
    "    print('RMSEP:', RMSEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import cross_validation\n",
    "from NIPALS import _NIPALS\n",
    "\n",
    "class Cross_Validation():  # Variable initialization\n",
    "\n",
    "    def __init__(self, x, y, n_fold, max_components):\n",
    "        self.x = x\n",
    "        self.y = y \n",
    "        self.n = x.shape[0]\n",
    "        self.n_fold = n_fold\n",
    "        self.max_components = max_components\n",
    "\n",
    "    def cv(self):  # Divide training sets and test sets\n",
    "        kf = cross_validation.KFold(self.n, self.n_fold)\n",
    "        x_train = []\n",
    "        y_train = []\n",
    "        x_test = [] \n",
    "        y_test = []\n",
    "\n",
    "        for train_index, test_index in kf:\n",
    "            xtr, ytr = self.x[train_index], self.y[train_index]\n",
    "            xte, yte = self.x[test_index], self.y[test_index]\n",
    "            x_train.append(xtr)\n",
    "            y_train.append(ytr)\n",
    "            x_test.append(xte)\n",
    "            y_test.append(yte)\n",
    "\n",
    "        return x_train, x_test, y_train, y_test\n",
    "\n",
    "    def predict_cv(self):\n",
    "        x_train, x_test, y_train, y_test = self.cv()\n",
    "        y_allPredict = np.ones((1, self.max_components))\n",
    "        pls = _NIPALS(self.max_components)\n",
    "\n",
    "        for i in range(self.n_fold):\n",
    "            y_predict = np.zeros((y_test[i].shape[0], self.max_components))\n",
    "            x_trainMean = np.mean(x_train[i], axis=0)\n",
    "            y_trainMean = np.mean(y_train[i], axis=0)\n",
    "            x_testCenter = np.subtract(x_test[i], x_trainMean)\n",
    "            list_coef_B = pls.fit(x_train[i], y_train[i], self.max_components)\n",
    "            for j in range(self.max_components):\n",
    "                y_pre = np.dot(x_testCenter, list_coef_B[j])\n",
    "                y_pre = y_pre + y_trainMean\n",
    "                y_predict[:, j] = y_pre.ravel()\n",
    "            y_allPredict = np.vstack((y_allPredict, y_predict))\n",
    "        y_allPredict = y_allPredict[1:]\n",
    "        return y_allPredict, self.y\n",
    "\n",
    "def mse_cv(self, y_allPredict, y_measure):\n",
    "\n",
    "        PRESS = np.square(np.subtract(y_allPredict, y_measure))\n",
    "        all_PRESS = np.sum(PRESS, axis=0)\n",
    "\n",
    "        RMSECV = np.sqrt(all_PRESS / self.n)\n",
    "        min_RMSECV = min(RMSECV)\n",
    "        comp_array = RMSECV.argsort()\n",
    "        comp_best = comp_array[0] + 1  \n",
    "\n",
    "        return RMSECV, min_RMSECV, comp_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draws_pre_pharm(Y_test, Y_predict, y_trainPredict, y_train):\n",
    " \n",
    "    plt.figure(figsize=(8, 8), facecolor='white')\n",
    "    plt.subplot(321) \n",
    "    plt.title('spectrometer1: weight')\n",
    "    plt.plot([min(y_train[0]), max(y_train[0])], [min(y_train[0]), max(y_train[0])], 'black', label='y=x')\n",
    "    plt.scatter(y_train[0], y_trainPredict[0], s=20, c='r', marker='o', label='calibration set')\n",
    "    plt.scatter(Y_test[0], Y_predict[0], s=30, c='b', marker='o', label='test set')\n",
    "    plt.xlabel('Measured value')\n",
    "    plt.ylabel(' Predicted value')\n",
    "    \n",
    "\n",
    "    plt.subplot(322)\n",
    "    plt.title(\"spectrometer1: hardness\") \n",
    "    plt.plot([min(y_train[1]), max(y_train[1])], [min(y_train[1]), max(y_train[1])], 'black', label='y=x')\n",
    "    plt.scatter(y_train[1], y_trainPredict[1], s=20, c='r', marker='o', label='calibration set')\n",
    "    plt.scatter(Y_test[1], Y_predict[1], s=30, c='b', marker='o', label='test set')\n",
    "    plt.xlabel('Measured value')\n",
    "    plt.ylabel(' Predicted value')\n",
    "\n",
    "    \n",
    "    plt.subplot(323) \n",
    "    plt.title(\"spectrometer1: assay\")\n",
    "    plt.plot([min(y_train[2]), max(y_train[2])], [min(y_train[2]), max(y_train[2])], 'black', label='y=x')\n",
    "    plt.scatter(y_train[2], y_trainPredict[2], s=20, c='r', marker='o', label='calibration set')\n",
    "    plt.scatter(Y_test[2], Y_predict[2], s=30, c='b', marker='o', label='test set')\n",
    "    plt.xlabel('Measured value')\n",
    "    plt.ylabel(' Predicted value')\n",
    "    \n",
    "    \n",
    "    plt.subplot(324) \n",
    "    plt.title(\"spectrometer2: weight\")\n",
    "    plt.plot([min(y_train[3]), max(y_train[3])], [min(y_train[3]), max(y_train[3])], 'black', label='y=x')\n",
    "    plt.scatter(y_train[3], y_trainPredict[3], s=20, c='r', marker='o', label='calibration set')\n",
    "    plt.scatter(Y_test[3], Y_predict[3], s=30, c='b', marker='o', label='test set')\n",
    "    plt.xlabel('Measured value')\n",
    "    plt.ylabel(' Predicted value')\n",
    "\n",
    "    \n",
    "    plt.subplot(325) \n",
    "    plt.title(\"spectrometer2: hardness\")\n",
    "    plt.plot([min(y_train[4]), max(y_train[4])], [min(y_train[4]), max(y_train[4])], 'black', label='y=x')\n",
    "    plt.scatter(y_train[4], y_trainPredict[4], s=20, c='r', marker='o', label='calibration set')\n",
    "    plt.scatter(Y_test[4], Y_predict[4], s=30, c='b', marker='o', label='test set')\n",
    "    plt.xlabel('Measured value')\n",
    "    plt.ylabel(' Predicted value')\n",
    "    \n",
    "    plt.subplot(326) \n",
    "    plt.title(\"spectrometer2: assay\")\n",
    "    plt.plot([min(y_train[5]), max(y_train[5])], [min(y_train[5]), max(y_train[5])], 'black', label='y=x')\n",
    "    plt.scatter(y_train[5], y_trainPredict[5], s=20, c='r', marker='o', label='calibration set')\n",
    "    plt.scatter(Y_test[5], Y_predict[5], s=30, c='b', marker='o', label='test set')\n",
    "    plt.xlabel('Measured value')\n",
    "    plt.ylabel(' Predicted value')\n",
    "   \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def rmsecv_comp_line_pharm(max_components, rmsecv_list):\n",
    "    \n",
    "    plt.figure(figsize=(8, 8), facecolor='white')\n",
    "    plt.subplot(321) \n",
    "    plt.title('spectrometer1: weight')\n",
    "    plt.plot(range(1, max_components + 1), rmsecv_list[0], '-o')\n",
    "    plt.xlabel('num_components')\n",
    "    plt.ylabel('RMSECV')\n",
    "\n",
    "    plt.subplot(322)\n",
    "    plt.title(\"spectrometer1: hardness\") \n",
    "    plt.plot(range(1, max_components + 1), rmsecv_list[1], '-o')\n",
    "    plt.xlabel('num_components')\n",
    "    plt.ylabel('RMSECV')\n",
    "    \n",
    "    plt.subplot(323) \n",
    "    plt.title(\"spectrometer1: assay\")\n",
    "    plt.plot(range(1, max_components + 1), rmsecv_list[2], '-o')\n",
    "    plt.xlabel('num_components')\n",
    "    plt.ylabel('RMSECV')   \n",
    "    \n",
    "    plt.subplot(324) \n",
    "    plt.title(\"spectrometer2: weight\")\n",
    "    plt.plot(range(1, max_components + 1), rmsecv_list[3], '-o')\n",
    "    plt.xlabel('num_components')\n",
    "    plt.ylabel('RMSECV')\n",
    "    \n",
    "    plt.subplot(325) \n",
    "    plt.title(\"spectrometer2: hardness\")\n",
    "    plt.plot(range(1, max_components + 1), rmsecv_list[4], '-o')\n",
    "    plt.xlabel('num_components')\n",
    "    plt.ylabel('RMSECV')\n",
    "       \n",
    "    plt.subplot(326) \n",
    "    plt.title(\"spectrometer2: assay\")\n",
    "    plt.plot(range(1, max_components + 1), rmsecv_list[5], '-o')\n",
    "    plt.xlabel('num_components')\n",
    "    plt.ylabel('RMSECV')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
